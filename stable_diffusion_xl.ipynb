{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# init\n",
    "import torch\n",
    "\n",
    "# for parameters ui\n",
    "import ipywidgets as widgets\n",
    "# for config\n",
    "import json\n",
    "# for saving results\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "# for image_grid\n",
    "from PIL import Image\n",
    "# for prompt embeddings\n",
    "from compel import Compel, ReturnedEmbeddingsType\n",
    "\n",
    "# hugging face cache directory\n",
    "CACHE_DIR = \"D:\\HuggingFaceCache\"\n",
    "# config path\n",
    "CONFIG_PATH = \"sdxl_config.json\"\n",
    "\n",
    "# import models, schedulers and etc\n",
    "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "from diffusers import EulerDiscreteScheduler, DDIMScheduler, LMSDiscreteScheduler\n",
    "\n",
    "class SDXLConfig:\n",
    "    def __init__(self, \n",
    "                 prompt: str = None,\n",
    "                 prompt_2: str = None,\n",
    "                 negative_prompt: str = None,\n",
    "                 negative_prompt_2: str = None,\n",
    "                 use_compel: bool = False,\n",
    "                 num_inference_steps: int = 40,\n",
    "                 width: int = 768,\n",
    "                 height: int = 768,\n",
    "                 guidance_scale: float = 7.5,\n",
    "                 high_noise_frac: float = 0.8,\n",
    "                 seed: int = 12345,\n",
    "                 use_refiner: bool = False\n",
    "                 ):\n",
    "        self.prompt = prompt\n",
    "        self.prompt_2 = prompt_2\n",
    "        self.negative_prompt = negative_prompt\n",
    "        self.negative_prompt_2 = negative_prompt_2\n",
    "        self.use_compel = use_compel\n",
    "        self.num_inference_steps = num_inference_steps\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.guidance_scale = guidance_scale\n",
    "        self.high_noise_frac = high_noise_frac\n",
    "        self.seed = seed\n",
    "        self.use_refiner = use_refiner\n",
    "\n",
    "    def to_json(obj):\n",
    "        if isinstance(obj, SDXLConfig):\n",
    "            return obj.__dict__\n",
    "    def from_json(dict: dict):\n",
    "            return SDXLConfig(**dict)\n",
    "    def load_config():\n",
    "         with open(CONFIG_PATH, \"r\") as read_file:\n",
    "            return json.load(read_file, object_hook=SDXLConfig.from_json)\n",
    "    def save_config(self):\n",
    "         with open(CONFIG_PATH, \"w\") as write_file:\n",
    "            json.dump(self, write_file, indent=1, default=SDXLConfig.to_json)\n",
    "            \n",
    "    def set_ui(self):\n",
    "        style = {'description_width': 'initial'}\n",
    "        prompt1_text_area = widgets.Textarea(value=self.prompt, placeholder='Type positive1...', description='Prompt1:', style=style)\n",
    "        display(prompt1_text_area)\n",
    "        prompt2_text_area = widgets.Textarea(value=self.prompt_2, placeholder='Type positive2...', description='Prompt2:', style=style)\n",
    "        display(prompt2_text_area)\n",
    "        negative_prompt1_text_area = widgets.Textarea(value=self.negative_prompt, placeholder='Type negative1...', description='Negative Prompt1:', style = style)\n",
    "        display(negative_prompt1_text_area)\n",
    "        negative_prompt2_text_area = widgets.Textarea(value=self.negative_prompt_2, placeholder='Type negative2...', description='Negative Prompt2:', style = style)\n",
    "        display(negative_prompt2_text_area)\n",
    "        use_compel_checkbox = widgets.Checkbox(value=self.use_compel, description=\"Use Compel\", indent=False, style=style)\n",
    "        display(use_compel_checkbox)\n",
    "\n",
    "        # inference properties\n",
    "        num_inference_steps_slider = widgets.IntSlider(value=self.num_inference_steps, min=10, max=100, step=5, description=\"Num inference steps:\", continuous_update=False, style=style)\n",
    "        display(num_inference_steps_slider)\n",
    "        width_slider = widgets.IntSlider(value=self.width, min=512, max=1024, step=64, description=\"Width:\", continuous_update=False, style=style)\n",
    "        display(width_slider)\n",
    "        height_slider = widgets.IntSlider(value=self.height, min=512, max=1024, step=64, description=\"Height:\", continuous_update=False, style=style)\n",
    "        display(height_slider)\n",
    "        guidance_scale_slider = widgets.FloatSlider(value=self.guidance_scale, min=0, max=10, step=0.25, description=\"Guidance scale:\", continuous_update=False, style=style)\n",
    "        display(guidance_scale_slider)\n",
    "        seed_slider = widgets.IntSlider(value=self.seed, min=0, max=1000000, step=1, description=\"Seed:\", continuous_update=False, style=style)\n",
    "        display(seed_slider)\n",
    "        high_noise_frac_slider = widgets.FloatSlider(value=self.high_noise_frac, min=0, max=1, step=0.05, description=\"High noise frac:\", continuous_update=False, style=style)\n",
    "        display(high_noise_frac_slider)\n",
    "\n",
    "        # refiner\n",
    "        use_refiner_checkbox = widgets.Checkbox(value=self.use_refiner, description=\"Use refiner\", indent=False, style=style)\n",
    "        display(use_refiner_checkbox)\n",
    "\n",
    "# utilities methods\n",
    "def to_cuda(pipe, start_mess, end_mess):\n",
    "    if(torch.cuda.is_available()):\n",
    "        print(start_mess)\n",
    "        pipe = pipe.to(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA IS NOT AVAILABLE\")\n",
    "    print(end_mess)\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "def postprocess_latent(pipe, latent):\n",
    "    vae_output = pipe.vae.decode(\n",
    "        latent.images / pipe.vae.config.scaling_factor, return_dict=False\n",
    "    )[0].detach()\n",
    "    return pipe.image_processor.postprocess(vae_output, output_type=\"pil\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62df33df22674e968e7fda48d7c8941e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='dsrs', description='Prompt1:', placeholder='Type positive1...', style=TextStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f1b513c0ab46fda60b660a795cd41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Prompt2:', placeholder='Type positive2...', style=TextStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ceb4275ed674e42bc8a580282fc76dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='ewrw', description='Negative Prompt1:', placeholder='Type negative1...', style=TextStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7227d5e19a74aa3b0080177de77a452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Negative Prompt2:', placeholder='Type negative2...', style=TextStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2810bcd79647fdad730be92fdb649f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Use Compel', indent=False, style=CheckboxStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d351b8acf6a44bb0a6e9aff4e6be0234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=40, continuous_update=False, description='Num inference steps:', min=10, step=5, style=SliderS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5a20df3cea4b3fb4d61ab492d120fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=768, continuous_update=False, description='Width:', max=1024, min=512, step=64, style=SliderSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3dbde659724519bca26cd9af8f007c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=768, continuous_update=False, description='Height:', max=1024, min=512, step=64, style=SliderS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a20a4f057942bd843572b814661640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=7.5, continuous_update=False, description='Guidance scale:', max=10.0, step=0.25, style=Slid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1c40eb179344f4ae09949e444fa93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=12345, continuous_update=False, description='Seed:', max=1000000, style=SliderStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a042a007a3c342e7af3c4ab7bea0b1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.8, continuous_update=False, description='High noise frac:', max=1.0, step=0.05, style=Slid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41dfbe762f8b4b2f8d3c16373aa9550c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Use refiner', indent=False, style=CheckboxStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ui\n",
    "config: SDXLConfig = SDXLConfig.load_config()\n",
    "config.set_ui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose models, schedulers types and etc\n",
    "base_model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "refiner_model = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "torch_dtype=torch.float16\n",
    "base_pipeline_type = StableDiffusionXLPipeline\n",
    "refiner_pipeline_type = StableDiffusionXLImg2ImgPipeline\n",
    "scheduler_type = LMSDiscreteScheduler\n",
    "variant=\"fp16\"\n",
    "use_safetensors=True\n",
    "#safety_checker = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline, set schelduler, to cuda, compel init and etc\n",
    "base_pipe = base_pipeline_type.from_pretrained(base_model, cache_dir=CACHE_DIR, \n",
    "                                               torch_dtype=torch_dtype,\n",
    "                                               variant=variant,\n",
    "                                               use_safetensors=use_safetensors)\n",
    "\n",
    "\n",
    "scheduler = scheduler_type.from_config(base_pipe.scheduler.config)\n",
    "base_pipe.scheduler = scheduler\n",
    "#base_pipe.unet = torch.compile(base_pipe.unet, mode=\"reduce-overhead\", fullgraph=True) # not for windows\n",
    "\n",
    "# base pipeline to CUDA\n",
    "to_cuda(base_pipe, \"Base -> CUDA started\", \"Base -> CUDA finished\")\n",
    "\n",
    "# Compels init (TODO: maybe should move \"generate image\" cell)\n",
    "base_compel_1 = Compel(\n",
    "    tokenizer=base_pipe.tokenizer,\n",
    "    text_encoder=base_pipe.text_encoder,\n",
    "    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "    requires_pooled=False,\n",
    ")\n",
    "base_compel_2 = Compel(\n",
    "    tokenizer=base_pipe.tokenizer_2,\n",
    "    text_encoder=base_pipe.text_encoder_2,\n",
    "    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "    requires_pooled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image\n",
    "\n",
    "# variables from ui\n",
    "prompt = str(prompt1_text_area.value)\n",
    "prompt_2 = str(prompt2_text_area.value)\n",
    "negative_prompt = str(negative_prompt1_text_area.value)\n",
    "negative_prompt_2 = str(negative_prompt2_text_area.value)\n",
    "print(f\"{prompt}\\n{prompt_2}\\n{negative_prompt}\\n{negative_prompt_2}\")\n",
    "\n",
    "use_compel = use_compel_checkbox.value\n",
    "num_inference_steps=num_inference_steps_slider.value\n",
    "guidance_scale=guidance_scale_slider.value\n",
    "use_refiner= \"latent\" if use_refiner_checkbox.value else \"pil\"\n",
    "high_noise_frac=high_noise_frac_slider.value\n",
    "width = width_slider.value\n",
    "height = height_slider.value\n",
    "seed = seed_slider.value\n",
    "\n",
    "config = SDXLConfig\n",
    "\n",
    "# set embeds\n",
    "base_positive_prompt_embeds_1 = base_compel_1(prompt)\n",
    "base_positive_prompt_embeds_2, base_positive_prompt_pooled = base_compel_2(prompt_2)\n",
    "base_negative_prompt_embeds_1 = base_compel_1(negative_prompt)\n",
    "base_negative_prompt_embeds_2, base_negative_prompt_pooled = base_compel_2(negative_prompt_2)\n",
    "\n",
    "# Pad the conditioning tensors to ensure thet they all have the same length\n",
    "(base_positive_prompt_embeds_2, base_negative_prompt_embeds_2) = base_compel_2.pad_conditioning_tensors_to_same_length([base_positive_prompt_embeds_2, base_negative_prompt_embeds_2])\n",
    "\n",
    "# Concatenate the cconditioning tensors corresponding to both the set of prompts\n",
    "base_positive_prompt_embeds = torch.cat((base_positive_prompt_embeds_1, base_positive_prompt_embeds_2), dim=-1)\n",
    "base_negative_prompt_embeds = torch.cat((base_negative_prompt_embeds_1, base_negative_prompt_embeds_2), dim=-1)\n",
    "\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "\n",
    "# base\n",
    "base_output = base_pipe(prompt=prompt if prompt != \"\" and not use_compel else None,\n",
    "                        prompt_2 = prompt_2 if prompt_2 != \"\" and not use_compel else None,\n",
    "                        negative_prompt = negative_prompt if negative_prompt != \"\" and not use_compel else None,\n",
    "                        negative_prompt_2 = negative_prompt_2 if negative_prompt_2 != \"\" and not use_compel else None,\n",
    "                        prompt_embeds=base_positive_prompt_embeds if base_positive_prompt_embeds != \"\" and use_compel else None,\n",
    "                        pooled_prompt_embeds=base_positive_prompt_pooled if base_positive_prompt_pooled != \"\" and use_compel else None,\n",
    "                        negative_prompt_embeds=base_negative_prompt_embeds if base_negative_prompt_embeds != \"\" and use_compel else None,\n",
    "                        negative_pooled_prompt_embeds=base_negative_prompt_pooled if base_negative_prompt_pooled != \"\" and use_compel else None,\n",
    "                        num_inference_steps=num_inference_steps,\n",
    "                        generator=generator,\n",
    "                        guidance_scale=guidance_scale,\n",
    "                        output_type=use_refiner,\n",
    "                        denoising_end=high_noise_frac,\n",
    "                        width=width,\n",
    "                        height=height)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refiner\n",
    "\n",
    "refiner_pipe = refiner_pipeline_type.from_pretrained(refiner_model, cache_dir=CACHE_DIR, \n",
    "                                    torch_dtype=torch_dtype,\n",
    "                                    variant=variant,\n",
    "                                    use_safetensors=use_safetensors,\n",
    "                                    vae=base_pipe.vae,\n",
    "                                    text_encoder_2=base_pipe.text_encoder_2)\n",
    "\n",
    "refiner_pipe.scheduler = scheduler\n",
    "#refiner_pipe.unet = torch.compile(refiner_pipe.unet, mode=\"reduce-overhead\", fullgraph=True) # not for windows\n",
    "\n",
    "# refiner pipeline to CUDA\n",
    "to_cuda(base_pipe, \"Refiner -> CUDA started\", \"Refiner -> CUDA finished\")\n",
    "\n",
    "\n",
    "image_refined = refiner_pipe(prompt=prompt if prompt != \"\" and not use_compel else None,\n",
    "                             prompt_2 = prompt_2 if prompt_2 != \"\" and not use_compel else None,\n",
    "                             negative_prompt = negative_prompt if negative_prompt != \"\" and not use_compel else None,\n",
    "                             negative_prompt_2 = negative_prompt_2 if negative_prompt_2 != \"\" and not use_compel else None,\n",
    "                             prompt_embeds=base_positive_prompt_embeds if base_positive_prompt_embeds != \"\" and use_compel else None,\n",
    "                             pooled_prompt_embeds=base_positive_prompt_pooled if base_positive_prompt_pooled != \"\" and use_compel else None,\n",
    "                             negative_prompt_embeds=base_negative_prompt_embeds if base_negative_prompt_embeds != \"\" and use_compel else None,\n",
    "                             negative_pooled_prompt_embeds=base_negative_prompt_pooled if base_negative_prompt_pooled != \"\" and use_compel else None,\n",
    "                             num_inference_steps=num_inference_steps,\n",
    "                             generator=generator,\n",
    "                             guidance_scale=guidance_scale,\n",
    "                             denoising_start=high_noise_frac_slider.value, \n",
    "                             image=base_output.images,\n",
    "                             #original_size = (height, width),\n",
    "                             #target_size = (height, width)\n",
    "                             ).images[0]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "display(image_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## old but gold stuff\n",
    "\n",
    "#if use_refiner_checkbox.value:\n",
    "    #base_pipe.to(\"cpu\")\n",
    "    #torch.cuda.empty_cache()\n",
    "    #torch.cuda.ipc_collect() \n",
    "    #unrefined_image = postprocess_latent(base_pipe, base_output)\n",
    "    #display(unrefined_image)\n",
    "#else:\n",
    "   #display(base_output.images[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
