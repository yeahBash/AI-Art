{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# importing\n",
    "import torch\n",
    "\n",
    "# for parameters ui\n",
    "import ipywidgets as widgets\n",
    "# for saving results\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "# for image_grid\n",
    "from PIL import Image\n",
    "# for prompt embeddings\n",
    "from compel import Compel, ReturnedEmbeddingsType\n",
    "\n",
    "# hugging face cache directory\n",
    "CACHE_DIR = \"D:\\HuggingFaceCache\"\n",
    "\n",
    "# import models, schedulers and etc\n",
    "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "from diffusers import EulerDiscreteScheduler, DDIMScheduler, LMSDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a151fd5c239f45df8b6bea790367f485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Prompt1:', placeholder='Type positive...', style=TextStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987784cd6480446eb814bcd2ec13a22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Prompt2:', placeholder='Type positive...', style=TextStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a512863ab093442aa232f904a11a41aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Negative Prompt1:', placeholder='Type negative...', style=TextStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47917cd1ee8f484cad7aacac67f920ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Negative Prompt2:', placeholder='Type negative...', style=TextStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d8e538a6a54befa4aab8ea4a98e4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Use Compel', indent=False, style=CheckboxStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816fde473bf5419696584ee53932b70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=40, description='Num inference steps:', min=10, step=5, style=SliderStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1990adbf2b164f4f92fa9f5a3edc0fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=768, description='Width:', max=1024, min=512, step=64, style=SliderStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b866dbef4fe5406e8b1543c23a6e1bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=768, description='Height:', max=1024, min=512, step=64, style=SliderStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e44654a64984b30a971d0822ed1e7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=7.5, description='Guidance scale:', max=10.0, step=0.25, style=SliderStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b6f06763ad46169e2dd6f731c880a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=12345, description='Seed:', max=1000000, style=SliderStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944b10c9c8b04139bda3879494e1eed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.8, description='High noise frac:', max=1.0, step=0.05, style=SliderStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d222c8eb199c4021adc87bdf218b5643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Use refiner', indent=False, style=CheckboxStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ui\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "# prompts\n",
    "prompt1_text_area = widgets.Textarea(value='', placeholder='Type positive...', description='Prompt1:', style=style)\n",
    "display(prompt1_text_area)\n",
    "prompt2_text_area = widgets.Textarea(value='', placeholder='Type positive...', description='Prompt2:', style=style)\n",
    "display(prompt2_text_area)\n",
    "negative_prompt1_text_area = widgets.Textarea(value='', placeholder='Type negative...', description='Negative Prompt1:', style = style)\n",
    "display(negative_prompt1_text_area)\n",
    "negative_prompt2_text_area = widgets.Textarea(value='', placeholder='Type negative...', description='Negative Prompt2:', style = style)\n",
    "display(negative_prompt2_text_area)\n",
    "use_compel_checkbox = widgets.Checkbox(value=False, description=\"Use Compel\", indent=False, style=style)\n",
    "display(use_compel_checkbox)\n",
    "\n",
    "# inference properties\n",
    "num_inference_steps_slider = widgets.IntSlider(value=40, min=10, max=100, step=5, description=\"Num inference steps:\", style=style)\n",
    "display(num_inference_steps_slider)\n",
    "width_slider = widgets.IntSlider(value=768, min=512, max=1024, step=64, description=\"Width:\", style=style)\n",
    "display(width_slider)\n",
    "height_slider = widgets.IntSlider(value=768, min=512, max=1024, step=64, description=\"Height:\", style=style)\n",
    "display(height_slider)\n",
    "guidance_scale_slider = widgets.FloatSlider(value=7.5, min=0, max=10, step=0.25, description=\"Guidance scale:\", style=style)\n",
    "display(guidance_scale_slider)\n",
    "seed_slider = widgets.IntSlider(value=12345, min=0, max=1000000, step=1, description=\"Seed:\", style=style)\n",
    "display(seed_slider)\n",
    "high_noise_frac_slider = widgets.FloatSlider(value=0.8, min=0, max=1, step=0.05, description=\"High noise frac:\", style=style)\n",
    "display(high_noise_frac_slider)\n",
    "\n",
    "# refiner\n",
    "use_refiner_checkbox = widgets.Checkbox(value=False, description=\"Use refiner\", indent=False, style=style)\n",
    "display(use_refiner_checkbox)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose models, schedulers types and etc\n",
    "torch_dtype=torch.float16\n",
    "base_model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "refiner_model = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "base_pipeline_type = StableDiffusionXLPipeline\n",
    "refiner_pipeline_type = StableDiffusionXLImg2ImgPipeline\n",
    "scheduler_type = LMSDiscreteScheduler\n",
    "variant=\"fp16\"\n",
    "use_safetensors=True\n",
    "#safety_checker = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ee35bd0504473cb9a9d2af200a5675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base->CUDA...\n"
     ]
    }
   ],
   "source": [
    "# load pipeline, set schelduler, to cuda, compel init and etc\n",
    "base_pipe = base_pipeline_type.from_pretrained(base_model, cache_dir=CACHE_DIR, \n",
    "                                               torch_dtype=torch_dtype,\n",
    "                                               variant=variant,\n",
    "                                               use_safetensors=use_safetensors)\n",
    "\n",
    "\n",
    "scheduler = scheduler_type.from_config(base_pipe.scheduler.config)\n",
    "base_pipe.scheduler = scheduler\n",
    "#base_pipe.unet = torch.compile(base_pipe.unet, mode=\"reduce-overhead\", fullgraph=True) # not for windows\n",
    "\n",
    "# base pipeline to CUDA\n",
    "if(torch.cuda.is_available()):\n",
    "    print(\"Base->CUDA...\")\n",
    "    base_pipe = base_pipe.to(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA IS NOT AVAILABLE\")\n",
    "    \n",
    "\n",
    "# if using torch < 2.0\n",
    "# pipe.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "# Compels init (TODO: maybe should move \"generate image\" cell)\n",
    "base_compel_1 = Compel(\n",
    "    tokenizer=base_pipe.tokenizer,\n",
    "    text_encoder=base_pipe.text_encoder,\n",
    "    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "    requires_pooled=False,\n",
    ")\n",
    "base_compel_2 = Compel(\n",
    "    tokenizer=base_pipe.tokenizer_2,\n",
    "    text_encoder=base_pipe.text_encoder_2,\n",
    "    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "    requires_pooled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batman, cinematic light, high resolution 3D render\n",
      "\n",
      "2d, low resolution, low quality, deformed face, deformed eyes, deformed hands, deformed fingers, rubbery skin, latex\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028c73cf187f4a54bf4f30cc9631cee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marve\\Projects\\Diffusers\\stable_diffusion_xl.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mGenerator(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmanual_seed(seed_slider\u001b[39m.\u001b[39mvalue)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# base\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m base_output \u001b[39m=\u001b[39m base_pipe(prompt\u001b[39m=\u001b[39;49mprompt \u001b[39mif\u001b[39;49;00m prompt \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m use_compel \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                         prompt_2 \u001b[39m=\u001b[39;49m prompt_2 \u001b[39mif\u001b[39;49;00m prompt_2 \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m use_compel \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m                         negative_prompt \u001b[39m=\u001b[39;49m negative_prompt \u001b[39mif\u001b[39;49;00m negative_prompt \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m use_compel \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                         negative_prompt_2 \u001b[39m=\u001b[39;49m negative_prompt_2 \u001b[39mif\u001b[39;49;00m negative_prompt_2 \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m use_compel \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m                         prompt_embeds\u001b[39m=\u001b[39;49mbase_positive_prompt_embeds \u001b[39mif\u001b[39;49;00m base_positive_prompt_embeds \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mand\u001b[39;49;00m use_compel \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                         pooled_prompt_embeds\u001b[39m=\u001b[39;49mbase_positive_prompt_pooled \u001b[39mif\u001b[39;49;00m base_positive_prompt_pooled \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mand\u001b[39;49;00m use_compel \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                         negative_prompt_embeds\u001b[39m=\u001b[39;49mbase_negative_prompt_embeds \u001b[39mif\u001b[39;49;00m base_negative_prompt_embeds \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mand\u001b[39;49;00m use_compel \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                         negative_pooled_prompt_embeds\u001b[39m=\u001b[39;49mbase_negative_prompt_pooled \u001b[39mif\u001b[39;49;00m base_negative_prompt_pooled \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mand\u001b[39;49;00m use_compel \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                         num_inference_steps\u001b[39m=\u001b[39;49mnum_inference_steps,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m                         generator\u001b[39m=\u001b[39;49mgenerator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m                         guidance_scale\u001b[39m=\u001b[39;49mguidance_scale,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m                         output_type\u001b[39m=\u001b[39;49moutput_type,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m                         denoising_end\u001b[39m=\u001b[39;49mdenoising_end,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m                         width\u001b[39m=\u001b[39;49mwidth,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m                         height\u001b[39m=\u001b[39;49mheight)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marve/Projects/Diffusers/stable_diffusion_xl.ipynb#W4sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32mc:\\Users\\marve\\Projects\\Diffusers\\.env\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\marve\\Projects\\Diffusers\\.env\\Lib\\site-packages\\diffusers\\pipelines\\stable_diffusion_xl\\pipeline_stable_diffusion_xl.py:831\u001b[0m, in \u001b[0;36mStableDiffusionXLPipeline.__call__\u001b[1;34m(self, prompt, prompt_2, height, width, num_inference_steps, denoising_end, guidance_scale, negative_prompt, negative_prompt_2, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, output_type, return_dict, callback, callback_steps, cross_attention_kwargs, guidance_rescale, original_size, crops_coords_top_left, target_size)\u001b[0m\n\u001b[0;32m    828\u001b[0m     noise_pred \u001b[39m=\u001b[39m rescale_noise_cfg(noise_pred, noise_pred_text, guidance_rescale\u001b[39m=\u001b[39mguidance_rescale)\n\u001b[0;32m    830\u001b[0m \u001b[39m# compute the previous noisy sample x_t -> x_t-1\u001b[39;00m\n\u001b[1;32m--> 831\u001b[0m latents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscheduler\u001b[39m.\u001b[39;49mstep(noise_pred, t, latents, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_step_kwargs, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    833\u001b[0m \u001b[39m# call the callback, if provided\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(timesteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m ((i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m>\u001b[39m num_warmup_steps \u001b[39mand\u001b[39;00m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39morder \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\marve\\Projects\\Diffusers\\.env\\Lib\\site-packages\\diffusers\\schedulers\\scheduling_lms_discrete.py:356\u001b[0m, in \u001b[0;36mLMSDiscreteScheduler.step\u001b[1;34m(self, model_output, timestep, sample, order, return_dict)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(timestep, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    355\u001b[0m     timestep \u001b[39m=\u001b[39m timestep\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimesteps\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 356\u001b[0m step_index \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimesteps \u001b[39m==\u001b[39;49m timestep)\u001b[39m.\u001b[39;49mnonzero()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m    357\u001b[0m sigma \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmas[step_index]\n\u001b[0;32m    359\u001b[0m \u001b[39m# 1. compute predicted original sample (x_0) from sigma-scaled predicted noise\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# generate image\n",
    "\n",
    "# variables from ui\n",
    "prompt = str(prompt1_text_area.value)\n",
    "prompt_2 = str(prompt2_text_area.value)\n",
    "negative_prompt = str(negative_prompt1_text_area.value)\n",
    "negative_prompt_2 = str(negative_prompt2_text_area.value)\n",
    "print(f\"{prompt}\\n{prompt_2}\\n{negative_prompt}\\n{negative_prompt_2}\")\n",
    "\n",
    "use_compel = use_compel_checkbox.value\n",
    "num_inference_steps=num_inference_steps_slider.value\n",
    "guidance_scale=guidance_scale_slider.value\n",
    "output_type= \"latent\" if use_refiner_checkbox.value else \"pil\"\n",
    "denoising_end=high_noise_frac_slider.value\n",
    "width = width_slider.value\n",
    "height = height_slider.value\n",
    "\n",
    "# set embeds\n",
    "base_positive_prompt_embeds_1 = base_compel_1(prompt)\n",
    "base_positive_prompt_embeds_2, base_positive_prompt_pooled = base_compel_2(prompt_2)\n",
    "base_negative_prompt_embeds_1 = base_compel_1(negative_prompt)\n",
    "base_negative_prompt_embeds_2, base_negative_prompt_pooled = base_compel_2(negative_prompt_2)\n",
    "\n",
    "# Pad the conditioning tensors to ensure thet they all have the same length\n",
    "(base_positive_prompt_embeds_2, base_negative_prompt_embeds_2) = base_compel_2.pad_conditioning_tensors_to_same_length([base_positive_prompt_embeds_2, base_negative_prompt_embeds_2])\n",
    "\n",
    "# Concatenate the cconditioning tensors corresponding to both the set of prompts\n",
    "base_positive_prompt_embeds = torch.cat((base_positive_prompt_embeds_1, base_positive_prompt_embeds_2), dim=-1)\n",
    "base_negative_prompt_embeds = torch.cat((base_negative_prompt_embeds_1, base_negative_prompt_embeds_2), dim=-1)\n",
    "\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed_slider.value)\n",
    "\n",
    "# base\n",
    "base_output = base_pipe(prompt=prompt if prompt != \"\" and not use_compel else None,\n",
    "                        prompt_2 = prompt_2 if prompt_2 != \"\" and not use_compel else None,\n",
    "                        negative_prompt = negative_prompt if negative_prompt != \"\" and not use_compel else None,\n",
    "                        negative_prompt_2 = negative_prompt_2 if negative_prompt_2 != \"\" and not use_compel else None,\n",
    "                        prompt_embeds=base_positive_prompt_embeds if base_positive_prompt_embeds != \"\" and use_compel else None,\n",
    "                        pooled_prompt_embeds=base_positive_prompt_pooled if base_positive_prompt_pooled != \"\" and use_compel else None,\n",
    "                        negative_prompt_embeds=base_negative_prompt_embeds if base_negative_prompt_embeds != \"\" and use_compel else None,\n",
    "                        negative_pooled_prompt_embeds=base_negative_prompt_pooled if base_negative_prompt_pooled != \"\" and use_compel else None,\n",
    "                        num_inference_steps=num_inference_steps,\n",
    "                        generator=generator,\n",
    "                        guidance_scale=guidance_scale,\n",
    "                        output_type=output_type,\n",
    "                        denoising_end=denoising_end,\n",
    "                        width=width,\n",
    "                        height=height)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if use_refiner_checkbox.value:\n",
    "    #base_pipe.to(\"cpu\")\n",
    "    #torch.cuda.empty_cache()\n",
    "    #torch.cuda.ipc_collect() \n",
    "    #unrefined_image = postprocess_latent(base_pipe, base_output)\n",
    "    #display(unrefined_image)\n",
    "#else:\n",
    "#display(base_output.images[0])\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect() \n",
    "    \n",
    "# utilities functions\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "def postprocess_latent(pipe, latent):\n",
    "    vae_output = pipe.vae.decode(\n",
    "        latent.images / pipe.vae.config.scaling_factor, return_dict=False\n",
    "    )[0].detach()\n",
    "    return pipe.image_processor.postprocess(vae_output, output_type=\"pil\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refiner\n",
    "\n",
    "refiner_pipe = refiner_pipeline_type.from_pretrained(refiner_model, cache_dir=CACHE_DIR, \n",
    "                                    torch_dtype=torch_dtype,\n",
    "                                    variant=variant,\n",
    "                                    use_safetensors=use_safetensors,\n",
    "                                    vae=base_pipe.vae,\n",
    "                                    text_encoder_2=base_pipe.text_encoder_2)\n",
    "\n",
    "refiner_pipe.scheduler = scheduler\n",
    "#refiner_pipe.unet = torch.compile(refiner_pipe.unet, mode=\"reduce-overhead\", fullgraph=True) # not for windows\n",
    "\n",
    "# refiner pipeline to CUDA\n",
    "if(torch.cuda.is_available()):\n",
    "    print(\"Refiner->CUDA...\")\n",
    "    refiner_pipe = refiner_pipe.to(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA IS NOT AVAILABLE\")\n",
    "\n",
    "image_refined = refiner_pipe(prompt=prompt if prompt != \"\" and not use_compel else None,\n",
    "                             prompt_2 = prompt_2 if prompt_2 != \"\" and not use_compel else None,\n",
    "                             negative_prompt = negative_prompt if negative_prompt != \"\" and not use_compel else None,\n",
    "                             negative_prompt_2 = negative_prompt_2 if negative_prompt_2 != \"\" and not use_compel else None,\n",
    "                             prompt_embeds=base_positive_prompt_embeds if base_positive_prompt_embeds != \"\" and use_compel else None,\n",
    "                             pooled_prompt_embeds=base_positive_prompt_pooled if base_positive_prompt_pooled != \"\" and use_compel else None,\n",
    "                             negative_prompt_embeds=base_negative_prompt_embeds if base_negative_prompt_embeds != \"\" and use_compel else None,\n",
    "                             negative_pooled_prompt_embeds=base_negative_prompt_pooled if base_negative_prompt_pooled != \"\" and use_compel else None,\n",
    "                             num_inference_steps=num_inference_steps,\n",
    "                             generator=generator,\n",
    "                             guidance_scale=guidance_scale,\n",
    "                             denoising_start=high_noise_frac_slider.value, \n",
    "                             image=base_output.images,\n",
    "                             #original_size = (height, width),\n",
    "                             #target_size = (height, width)\n",
    "                             ).images[0]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "display(image_refined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
